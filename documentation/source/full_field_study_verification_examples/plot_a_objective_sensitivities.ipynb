{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Objective Sensitivity Study\nIn this example, we perform \na sensitivity study\nwhere we observe how several objectives\nvary as we change the material parameters \nby +/- 5% from the values \nused to generate the synthetic data. \nWe do this for only one data set, \nthe ``0_degree`` data set, because \nwe wish to gauge whether it is\npossible to calibrate \nall parameters to one data set. \n\nWe are going to assess the sensitivity of \nfive objectives to the input parameters:\n\n#. The :class:`~matcal.core.objective.CurveBasedInterpolatedObjective` \n   for the load-displacement curve.\n#. The :class:`~matcal.full_field.objective.InterpolatedFullFieldObjective`\n   for the X and Y displacements.\n#. The :class:`~matcal.full_field.objective.PolynomialHWDObjective`\n   without point colocation.\n#. The :class:`~matcal.full_field.objective.PolynomialHWDObjective`\n   with point colocation.\n#. The :class:`~matcal.full_field.objective.MechanicalVFMObjective`\n   used with the :class:`~matcal.sierra.models.VFMUniaxialTensionHexModel`.\n\nTo begin, we import the MatCal tools necessary for this study\nand import the data that will be used for the calibration.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from matcal import *\nimport numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we import the data\nwe wish to use in the study. \nFor this study, we must import \nthe same data set twice. This \nis because we need to \nhave displacement named something \nother than \"displacement_(x,y,z)\"\nfor the VFM model and the other \nmodel will need to compare \nto \"displacement_(x,y)\" for their \nobjective. We could also output \ndisplacement as another name from \nSierraSM, but then some visualization \nsoftware would not automatically load\nthe deformed configuration. Renaming fields\nand importing the data twice is simple\nwith MatCal's `Data Importing and Manipulation`\nTools. \n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "synthetic_data = FieldSeriesData(\"synthetic_data_files/synthetic_surf_results_0_degree.e\")\nsynthetic_data.rename_field(\"U\", \"displacement_x\")\nsynthetic_data.rename_field(\"V\", \"displacement_y\")\nsynthetic_data.rename_field(\"W\", \"displacement_z\")\n\nvfm_data = FieldSeriesData(\"synthetic_data_files/synthetic_surf_results_0_degree.e\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After importing the data, we\nselect the data we want to use for our study.\nFor the load-displacement curve objective, \nwe want all time steps up to 92.5% of the peak load \npast peak load. These data are selected \nfor the ``synthetic_data`` object below. \nFor the HWD and interpolate full-field \nobjectives, we select only three time steps. \nOne is early in the load-displacement history, \nthe second is at peak load, and the third is \nat 92.5% of peak load past peak load. We call \nthis truncated data ``selected_data``. \nThe final ``vfm_data`` contains all data before \npeak load where VFM is valid.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "peak_load_arg = np.argmax(synthetic_data[\"load\"])\nlast_desired_arg = np.argmin(np.abs(synthetic_data[\"load\"]\\\n                                    [peak_load_arg:]-np.max(synthetic_data[\"load\"])*0.925))\nsynthetic_data = synthetic_data[:last_desired_arg+1+peak_load_arg]\nsynthetic_data.set_name(\"0_degree\")\n\nlast_disp_arg = np.argmax(synthetic_data[\"displacement\"])\nselected_data = synthetic_data[[200, peak_load_arg, last_disp_arg]]\nselected_data.set_name(\"selected data\")\n\nvfm_data = vfm_data[vfm_data[\"displacement\"] < 0.036]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With the data imported and selected, \nwe plot the data to verify our \ndata manipulations.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dc = DataCollection(\"synthetic\", synthetic_data, selected_data)\ndc.plot(\"displacement\", \"load\")\nimport matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Above, we can see the data we selected\nin orange and verify these are the points of interest.\nNext, we plot the displacement fields. \nWe plot the deformed configuration colored\naccording the correct displacement field on top of the undeformed \nconfiguration in grey. \n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def plot_field(data, field, ax):\n    c = ax.scatter(1e3*(data.spatial_coords[:,0]), \n                   1e3*(data.spatial_coords[:,1]), \n                   c=\"#bdbdbd\", marker='.', s=1, alpha=0.5)\n    c = ax.scatter(1e3*(data.spatial_coords[:,0]+data[\"displacement_x\"][-1, :]), \n                   1e3*(data.spatial_coords[:,1]+data[\"displacement_y\"][-1, :]), \n                   c=1e3*data[field][-1, :], marker='.', s=3)\n    ax.set_xlabel(\"X (mm)\")\n    ax.set_ylabel(\"Y (mm)\")\n    direction = data.state.name.replace(\"_\", \" \")\n    ax.set_title(f\"{direction}\")\n    ax.set_aspect('equal')\n    fig.colorbar(c, ax=ax, label=f\"{field} mm\")\n\nfig, axes = plt.subplots(1,2, constrained_layout=True)\nplot_field(synthetic_data, \"displacement_x\", axes[0])\nplot_field(synthetic_data, \"displacement_y\", axes[1])\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After importing and preparing the data, \nwe create the models that will be used \nto simulate the characterization test. \nWe will make both a :class:`~matcal.sierra.models.UserDefinedSierraModel`\nand a :class:`~matcal.sierra.models.VFMUniaxialTensionHexModel`\nfor this example. Both of these models will need the same \nSierraSM material model input file. We create it \nnext using Python string and file tools.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "mat_file_string = \"\"\"begin material test_material\n  density = 1\n  begin parameters for model hill_plasticity\n    youngs modulus  = {elastic_modulus*1e9}\n    poissons ratio  = {poissons}\n    yield_stress    = {yield_stress*1e6}\n\n    hardening model = voce\n    hardening modulus = {A*1e6}\n    exponential coefficient = {n}\n\n    coordinate system = rectangular_coordinate_system\n\n    R11 = {R11}\n    R22 = {R22}\n    R33 = {R33}\n    R12 = {R12}\n    R23 = {R23}\n    R31 = {R31}\n  end\nend\n\"\"\"\n\nwith open(\"modular_plasticity.inc\", 'w') as fn:\n    fn.write(mat_file_string)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With the material file created, \nthe models can be instantiated. \nWe start with the :class:`~matcal.sierra.models.UserDefinedSierraModel`\nand point it to the correct user-supplied \ninput deck and mesh. For this model, \nwe use ``adagio`` as the \nsolid mechanics simulation code. We use the appropriate model \nmethods to set up the model for the study.\nMost importantly, we pass the correct \nmodel constants to it and tell the model \nto read the full field data results \nfrom the output exodus file.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model = UserDefinedSierraModel(\"adagio\", \"synthetic_data_files/test_model_input_reduced_output.i\", \n                               \"synthetic_data_files/test_mesh.g\", \"modular_plasticity.inc\")\nmodel.set_name(\"3D_model\")\nmodel.add_constants(elastic_modulus=200, poissons=0.27, \n                    R22=1.0, R33=0.9, R23=1.0, R31=1.0)\nmodel.set_number_of_cores(112)\nmodel.read_full_field_data(\"surf_results.e\")\n\nfrom matcal.sandia.computing_platforms import is_sandia_cluster\nif is_sandia_cluster():       \n    model.run_in_queue(\"fy220213\", 0.5)\n    model.continue_when_simulation_fails()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The VFM model requires a :class:`~matcal.sierra.material.Material`\nobject. After creating the material object, we \ncreate the VFM model with the correct surface mesh \nthat corresponds to our output surface mesh and the total \nspecimen thickness. Similar to the previous model,\nwe use the correct methods to prepare the model \nfor the study.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "material = Material(\"test_material\", \"modular_plasticity.inc\", \"hill_plasticity\")\nvfm_model = VFMUniaxialTensionHexModel(material, \n                                       \"synthetic_data_files/test_mesh_surf.g\", \n                                       0.0625*0.0254)\nvfm_model.add_boundary_condition_data(vfm_data)\nvfm_model.set_name(\"vfm_model\")\nvfm_model.set_number_of_cores(36)\nvfm_model.set_number_of_time_steps(450)\nvfm_model.add_constants(elastic_modulus=200, poissons=0.27, R22=1.0, \n                        R33=0.9, R23=1.0, R31=1.0)\nif is_sandia_cluster():       \n    vfm_model.run_in_queue(\"fy220213\", 10.0/60.0)\n    vfm_model.continue_when_simulation_fails()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The objectives that we wish to evaluate \nare created next.\nAll full-field objectives are given the correct \ninput parameters to function correctly for the planned study.\nPrimarily, this the mesh that they will interpolate the experiment\ndata onto and the fields that will be compared. \n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "interpolate_objective = InterpolatedFullFieldObjective(\"synthetic_data_files/test_mesh_surf.g\", \n                                                       \"displacement_x\", \n                                                       \"displacement_y\")\ninterpolate_objective.set_name(\"interpolate_objective\")\n\nhwd_colocated_objective = PolynomialHWDObjective(\"synthetic_data_files/test_mesh_surf.g\", \n                                                 \"displacement_x\", \n                                                 \"displacement_y\")\nhwd_colocated_objective.set_name(\"hwd_colocated_objective\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A special case is the :class:`~matcal.full_field.objective.PolynomialHWDObjective`,\nwhere the first input argument is ``None``. The first \nargument is the mesh or point cloud that the fields will \nbe mapped to. If ``None`` is passed, no interpolation is performed,\nand standard HWD without co-location is used. This should only \nbe done for cases where the simulation mesh has its surface area\ncompletely within the experimental data. Otherwise, the objective\nwill likely be invalid. \n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "hwd_objective = PolynomialHWDObjective(None, \"displacement_x\", \n                                       \"displacement_y\")\nhwd_objective.set_name(\"hwd_objective\")\n\nload_objective = CurveBasedInterpolatedObjective(\"displacement\", \"load\", right=0)\nload_objective.set_name(\"load_objective\")\n\nvfm_objective = MechanicalVFMObjective()\nvfm_objective.set_name(\"vfm_objective\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We then create the material model \ninput parameters for the study with the initial point being \nthe values used to generate the synthetic data, or \nthe \"truth\" values.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "Y = Parameter(\"yield_stress\", 150, 250.0, 200.0)\nA = Parameter(\"A\", 1250, 2000, 1500.0)\nn = Parameter(\"n\", 1, 4, 2.00)\nR11 = Parameter(\"R11\", 0.8, 1.1, 0.95)\nR12 = Parameter(\"R12\", 0.7, 1.1 , 0.85)\n\nparam_collection = ParameterCollection(\"Hill48 in-plane\", Y, A, n, R11, R12)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The :class:`~matcal.core.parameter_studies.ParameterStudy` is created,\nand all evaluation sets are added. \n\n<div class=\"alert alert-info\"><h4>Note</h4><p>MatCal will only run the ``3D_model`` once even though it is added \n   multiple times. Only the extra objectives will be added \n   to the additional evaluation sets.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "study = ParameterStudy(param_collection)\nstudy.set_core_limit(51)\nstudy.add_evaluation_set(vfm_model, vfm_objective, vfm_data)\nstudy.add_evaluation_set(model, load_objective, synthetic_data)\nstudy.add_evaluation_set(model, interpolate_objective, selected_data)\nstudy.add_evaluation_set(model, hwd_objective, selected_data)\nstudy.add_evaluation_set(model, hwd_colocated_objective, selected_data)\nstudy.set_working_directory(\"objective_sensitivity_study\", remove_existing=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The final step is to add the parameter values to be evaluated. \nFirst, we add the truth values, which should be\nthe minimum for all objectives. Next, we add 10 values \nfrom -5% to +5% for each parameter.\nOnly one parameter is varied at a time to simplify visualization. The function \nbelow adds the parameter evaluations to the study.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "study.add_parameter_evaluation(**param_collection.get_current_value_dict())\nevaluations = []\nimport copy\nfor name, param in param_collection.items():\n    for val in np.linspace(param.get_current_value()*0.95,param.get_current_value()*1.05, 10):\n        current_eval = copy.copy(param_collection.get_current_value_dict())\n        current_eval[name]=val\n        evaluations.append(current_eval)\n        study.add_parameter_evaluation(**current_eval)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we launch the study and plot the results.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "results = study.launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Several plots are output below, and \nwe summarize the results here.\n\n#. VFM objective observations: \n   The first plot shows the VFM objective plotted \n   for each parameter evaluation. As the \n   input parameters change the objective increases\n   and decreases smoothly with well defined \n   local minima. One issue is \n   that the first parameter set evaluated, \n   which corresponds to the values \n   used to generate the synthetic data is \n   not the lowest. This is due to the \n   model form error introduced by the \n   plane stress assumption, and is expected. \n   The shift in the global minimum is most \n   obvious in the third plot, which shows \n   how the objective varies with input parameters. \n   The vertical lines of evaluations are the \n   changes of the other parameters and should \n   be where the global minimum is located. \n   However, for each parameter, there exists\n   at least one different local minimum\n   that shifted slightly to one side in the parameter\n   space from the expected minimum. The actual \n   global minimum is likely somewhere else within the \n   multi-dimensional objective function space.\n#. Load-displacement objective observations:\n   The upper right subplot, for the second image, \n   shows how the load-displacement objective \n   changes with the parameters. It has a clear \n   minimum at the expected global minimum at \n   the first parameter evaluation. Overall, the objective is less\n   smooth than the VFM objective across all evaluations. The first subplot \n   of the fourth figure shows the objective \n   sensitivity to the individual parameters. \n   Here, again, the minimum is at the expected global \n   minimum. One issue for calibration is that the \n   objective has a what seems like a discontinuity\n   or at least a sharp drop to the right and left \n   of the minimum. This \n   sharp change in the objective will be \n   problematic for gradient methods and \n   is likely more complex in the full \n   five-dimensional space of the objective.\n#. Full-field interpolation and HWD objective observations:\n   The HWD objective without point colocation and \n   the full-field interpolation objectives \n   produce similar results. This is expected, \n   as the HWD objective is a linear transform \n   of the displacement field and is a very similar \n   comparison. The objective values for the methods\n   as a function of parameter evaluation are shown in the \n   top right and bottom left of the second \n   figure. Both figures show the same general objective \n   landscape with their minima at the expected global \n   minimum. There are two noticeable differences: (1)\n   the HWD objective has a lower overall magnitude \n   since the normalization routine scales the objective\n   slightly differently and (2) there is a much lower \n   objective at the expected global minimum for HWD. \n   The high objective values for the interpolation method \n   at the global minimum is due to small errors introduced \n   by interpolation. \n#. HWD objective with colocation observations:\n   The HWD objective with colocation results \n   are\n   very similar to the HWD objective without \n   colocation, however, the global \n   minimum at the true parameter values is not \n   as low. This is due to the error introduced\n   by interpolation. Also, as the objective \n   function changes with $n$, the minimum \n   is less clearly defined. This is likely due to \n   the error introduced by both the HWD transform and \n   spatial interpolation, \n   causing this parameter to be less clearly identified.\n\nIn summary, these results show that the objectives are \nbehaving as expected, and that the implementation of the methods\nand their execution through the MatCal study interface are verified.\nThese results also suggest that VFM will behave well with gradient methods, \nbut will provide measurable errors in the parameters. The other\nmethods should return the correct parameters, but will be more \nchallenging to identify the true global minimum with \nthe less-convex objective landscape. Interestingly, \nthe full-field data objectives all provide a more \nfavorable objective function for optimization \nthan the load-displacement objective. We suspect \nthat for this problem, using the full-field objectives alone\nwould provide quality calibrations. However, full-field\nobjectives should \nnot be used alone in practice, because the existence of model form error would \nlikely yield invalid parameters for the external \nloads for simulations of the material characterization\ntests. \n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import os\ninit_dir = os.getcwd()\nos.chdir(\"objective_sensitivity_study\")\nmake_standard_plots(\"time\",\"displacement\",\"weight_id\",\"displacement_x\", \n                    plot_model_objectives=True)\nos.chdir(init_dir)\n\n# sphinx_gallery_thumbnail_number = 4"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}