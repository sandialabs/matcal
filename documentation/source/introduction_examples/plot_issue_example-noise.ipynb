{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Data Noise Issue - Low and High Noise Example\nIn this case the data comes from the same model as the one we are calibrating. \nThe model is a bilinear function similar to elastic-plastic \nresponse with the parameter \"Y\" controlling where change from one linear \ntrend to the other takes place and the parameter \"H\" controlling the slope of the second trend. \nThe slope of the initial trend is fixed, as if it were known (as the elastic modulus typically would be).\n\nThe fits for the low and high noise cases look similar; however, \nif the error as a function of the parameters is examined you can see: \n(a) the optimum has shifted and (b) the bowl is flatter for the high noise case. \nThe noise induces bias in the optimal parameters and \nmakes the problem harder to solve. With enough noise \nthe calibration becomes useless. Also, it is apparent from \nthe shape of the error contours the two parameters Y and H \nhave correlated effects on the error, i.e., combinations of \nhigh Y and low H have the same error as low Y and high H. \nThis is common in physics models and presents a tradeoff in \ncalibration that in its extreme becomes another issue \n(which will be explored in another example  targeting \"identifiability\").\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# sphinx_gallery_thumbnail_number = 4\n\nfrom matcal import *\nimport numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We create a python function to be used as a MatCal PythonModel\nfor this calibration. The python model uses Numpy in the function\nand requires that Numpy be imported within the function.\nAs stated above, the data will be fitted to a model with a \nbilinear response similar to an elastic-plastic model.\nThe initial slope (E) is assumed to be known. \nThe parameter \"Y\" determines where the model changes to \nthe second linear trend and the parameters \"H\" determines the second slope.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def bilinear_model(**parameters):\n  import numpy as np\n  max_strain = 1.0\n  npoints = 100\n  strain = np.linspace(0,max_strain,npoints)\n  E = 1.5\n  Y = parameters['Y']\n  H = parameters['H']\n  eY = Y/E\n  stress = np.where(strain < eY, E*strain, Y + H*(strain-eY))\n  response = {'strain':strain, 'stress': stress}\n  return response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With the function for the model defined above,\nwe create the parameters for our MatCal \ncalibration study and the MatCal PythonModel\nfrom the function.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "Y = Parameter('Y',0.0,1.0, 0.501)\nH = Parameter('H',0.0,1.0, 0.501)\nparameters = ParameterCollection('parameters', Y, H)\n\nmodel = PythonModel(bilinear_model)\nmodel.set_name(\"bilinear\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Start with low noise fit.\nA simple gradient-based calibration with a \nmean squared error objective is enough to illustrate the point. \nWe load the data, create the calibration based on the model parameters, \nand define an objective of fitting the model response to the data.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data_low_noise = FileData('bilinear_lownoise.csv')\ncalibration = GradientCalibrationStudy(parameters)\nobjective = CurveBasedInterpolatedObjective('strain','stress')\ncalibration.add_evaluation_set(model, objective, data_low_noise)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After running the calibration, we \nload the optimal parameters and the best fit.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "results = calibration.launch()\nbest_parameters_low_noise = results.best.to_dict()\nbest_response = results.best_simulation_data(model, 'matcal_default_state')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can then run the calibration and load the optimal parameters and the best fit.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data_strain_low_noise = data_low_noise['strain']\ndata_stress_low_noise = data_low_noise['stress']\nmodel_strain = best_response['strain']\nmodel_stress = best_response['stress']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First let us compare the response curves.\nWe plot the calibrated model with lines and \nthe data with points. Generally, there are about as \nmany points above the fitted line as below. \nThis is due to using a mean squared error objective.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nplt.plot(model_strain, model_stress,'b',label=\"fit\")\nplt.scatter(data_strain_low_noise,data_stress_low_noise,2,'r',label=\"data\")\nplt.xlabel(\"STRAIN\")\nplt.ylabel(\"STRESS\")\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Second, examine how the error changes in the vicinity of the best fit.\nThis a helper function to evaluate the \nerror on a grid of parameter values for plotting. \nMatCal's ParameterStudy can also do this.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def sample_error(model, data, ranges = {\"Y\":[0.0,0.2],\"H\":[0.0,0.2]} ):\n  Ys, Hs = np.mgrid[ ranges[\"Y\"][0]:ranges[\"Y\"][1]:100j, ranges[\"H\"][0]:ranges[\"H\"][1]:100j]\n  Zs = np.empty_like(Ys)\n  for i in range(Ys.shape[0]):\n    for j in range(Ys.shape[1]):\n      parameters = {\"Y\":Ys[i,j],\"H\":Hs[i,j]}\n      response = model(**parameters)\n      residual = response['stress']-data['stress']\n      error = np.sum(residual**2)\n      Zs[i,j] = error\n  return Ys,Hs,Zs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The contour plot depicts the change in error in the vicinity of the optimum.\nClearly it rises smoothly from the minimum at the optimum.\nIf viewed from the side the error vs. parameters would \nlook like a parabola with an elliptical cross-section.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "Ys,Hs,Zs = sample_error(bilinear_model,data_low_noise)\nplt.contourf(Ys,Hs,np.log(Zs),20)\nplt.grid(True)\nplt.xlabel(\"Y\")\nplt.ylabel(\"H\")\nplt.colorbar(label=\"log error\")\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now do the high noise fit.\nLoad data from the same model as \nthe one to be fitted with added uncorrelated \nnoise but now with more (higher variance) noise.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data_high_noise = FileData('bilinear_highnoise.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We again create the parameters, but this \ntime slightly change the initial point to \nget around a known issue with Dakota. \nSee the note below. \n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "Y = Parameter('Y',-10.0,2.0, 0.4999) # note jiggle initial value to get around dakota issue\nH = Parameter('H',-1.0,2.0, 0.4999) # note jiggle initial value to get around dakota issue"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        ".. include:: ../multiple_dakota_studies_in_python_instance_warning.rst\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "parameters = ParameterCollection('parameters', Y, H)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Again, a simple gradient-based calibration \nwith a mean squared error objective is used to perform the calibration.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "calibration = GradientCalibrationStudy(parameters)\ncalibration.add_evaluation_set(model, objective, data_high_noise)\nresults = calibration.launch()\nbest_parameters_high_noise = results.best.to_dict()\nbest_response = results.best_simulation_data(model, 'matcal_default_state')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Grab the true/experimental response and the model/fitted response\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data_strain_high_noise = data_high_noise['strain']\ndata_stress_high_noise = data_high_noise['stress']\nmodel_strain = best_response['strain']\nmodel_stress = best_response['stress']\n\nimport matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Compare the response curves. \nWe plot the calibrated model with lines and \nthe data with points. Again, there are about as many \npoints above the fitted line as below, but you can see \nif the spread in the data becomes larger the slope and \nthe change-over point will become less well defined.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.plot(model_strain,model_stress,'b',label=\"fit\")\nplt.scatter(data_strain_low_noise,data_stress_high_noise,2,'r',label=\"data\")\nplt.xlabel(\"STRAIN\")\nplt.ylabel(\"STRESS\")\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Once again, examine how the error changes in the vicinity of the best fit.\nThe bottom of the error bowl, depicted by the contours, is now not centered \non the true parameter values Y=0.1, H=0.1. The contours are still elliptical, \nbut the slope of the bowl is shallower. In the limit the bowl can become \nso shallow that the descent direction may be hard to determine.\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "Ys,Hs,Zs = sample_error(bilinear_model,data_high_noise)\nplt.contourf(Ys,Hs,np.log(Zs),20)\nplt.grid(True)\nplt.xlabel(\"Y\")\nplt.ylabel(\"H\")\nplt.colorbar(label=\"log error\")\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}