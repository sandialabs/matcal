{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Surrogate Generation Example\n\nThis example demonstrates how to generate a basic surrogate from a MatCal study.\nThis example will cover:\n\n* Generating a base data set for surrogate generation\n* Generating a surrogate from a MatCal Study\n* Obtaining predictions from a surrogate \n* How to load a saved surrogate\n* How to launch an interactive window for interrogating a surrogate \n\nThe problem of interest is the uncertainty surrounding the boundary \nconditions for a foam and metal component in a high temperature environment.\nIn this problem, a layer of foam separates two layers of steel. The top layer of \nsteel is heated from a far field radiative source and convective heating from the heated\ngas surrounding it. We are concerned with the temperature rise immediately behind both metal layers.\nThe temperature of the gas, the temperature\nof the far field source, and the speed of the ambient gas are uncertain. \n\nThis problem can be solved directly using a finite element simulation.\nHowever for large UQ analysis or complicated calibrations, the evaluation time of the \nfinite element simulation can cause studies that require many evaluations of the model \nto be prohibitively long. Using surrogates\nas a replacement for higher-fidelity simulations offers an approach to reduce the\nseverity of these challenges. Surrogates can enable advanced analysis techniques such as \nBayesian calibration or Multi-fidelity modeling. \n\nSurrogates in MatCal are data-based curve fits to predictions from higher fidelity \nsimulations. As such they require an initial body (the word 'corpus' is often used as well)\nof data to be constructed, but then allow for near instant evaluation for future predictions. \nTo generate this body of data, a large initial battery of simulations must be run. \nTo do this in MatCal, we will run an LHS sampling study. An LHS study will allow us\nto efficiently sample our prediction space. \n\nThe need to run a large battery of simulations before one gets a surrogate begs the question\n'Why should I spend the time to generate a surrogate when I could just run my study with \nmy high fidelity model?' This is an appropriate question, for simple small analyses \ngenerating a surrogate model is not worth the upfront cost but, as the analysis gets \nmore complicated and model evaluations more numerous,\nhaving a surrogate for relevant quantities of \ninterest can save a lot of time. In addition, generating the body of data necessary \nfor building a surrogate is often extremely parallelizable, thus with sufficient\ncomputing resources all of the necessary simulations can be run in a few \nsimultaneous batches.\n\nTo generate a surrogate that predicts the heating behavior for a given set of boundary conditions,\nwe start this example by importing MatCal and numpy.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# sphinx_gallery_thumbnail_number = 6\nimport matcal as mc\nimport numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For this example there are three parameters that define our boundary conditions. \nthe convective heat transfer coefficient, H, relates how rapidly energy is exchanged\nbetween the ambient gas and the solid components, it is closely related to the speed of \nthe ambient gasses. We will use it as an abstraction for how fast the gasses \nare moving around our component.\nAir values of H near 1 are characteristic of low flow environments, \nvalues near 10 are for conditions of moderate\nflow, and values near 100 are for conditions of strong flow. \nThe other two parameters of interest are \nthe temperatures of the air and a far field heat source. The ranges of \nthese values were chosen to \nbe on the order of temperatures seen near a fire. \n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "conv_heat_transfer_coeff = mc.Parameter(\"H\", 1, 100) # W / (m^2 K)\nfar_field_temperature = mc.Parameter(\"T_inf\", 500, 1000) # K\nair_temperature = mc.Parameter(\"T_air\", 400, 800) # K"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We then load these parameters into a Latin Hypercube Sensitivity Study. This is the \nstudy that will be used to generate our body of training data for the surrogate. \nFor more details see :class:`~matcal.dakota.sensitivity_studies.LhsSensitivityStudy`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sampling_study = mc.LhsSensitivityStudy(conv_heat_transfer_coeff, far_field_temperature, \n                                        air_temperature)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Through defining an objective for the LHS, we define what our independent and dependent fields of \ninterest are. In this case, we want to use 'time' as our independent field. Since\nwe do not need to compare to experimental data for this study, \nwe will use a :class:`~matcal.core.objective.SimulationResultsSynchronizer`\nin place of the objective. It needs the independent field, \nthe values of interest for the independent field and any dependent fields\nof interest for the study and resulting surrogate.\nWhen determining the independent field values of interest, it is important\nto select an appropriate number of prediction points. For more complicated \nphysical evolutions, selecting too few points will generate poor surrogates. \n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "n_prediction_points = 200\ntime_start = 0\ntime_end = 60 * 60 * 2\nindep_field_vals = np.linspace(time_start, time_end, n_prediction_points)\nmy_objective = mc.SimulationResultsSynchronizer('time', indep_field_vals,\n                                                 \"TC_top\", \"TC_bottom\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we need to inform MatCal about our high fidelity model. Our model \nis a SIERRA/aria model that we define in a local subdirectory 'aria_model'. \n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "my_hifi_model = mc.UserDefinedSierraModel('aria', \"aria_model/metal_foam_layers.i\", \n                                          \"aria_model/test_block.g\", \"aria_model/include\")\nmy_hifi_model.set_results_filename(\"results/results.csv\")\nmy_hifi_model.set_number_of_cores(12)\nfrom site_matcal.sandia.tests.utilities import MATCAL_WCID\n\nmy_hifi_model.run_in_queue(MATCAL_WCID, 0.25)\nmy_hifi_model.continue_when_simulation_fails()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we have all of our necessary components for a LHS study. We pass our \nmodel and objective into the study. We then tell our study \nhow many cores its can use and the number of samples it needs to run. \nWe chose 500 samples for this example because it has a decent performance floor \nand runs in a reasonable amount of time. Depending on the complexity of your problem, \na larger sample set may be required (1000-10000). \n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sampling_study.add_evaluation_set(my_hifi_model, my_objective)\nsampling_study.set_core_limit(250)\nsampling_study.set_number_of_samples(500)\nsampling_study.set_seed(12345)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With our study defined, we run it and wait for it to complete. \nWhile it will generate information with regards to the sensitivity of the \nquantities of interest to the parameters, we are mostly interested in the model\nresults the study produced. \n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "study_results = sampling_study.launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that the study is done running, we will generate a surrogate for the model\nusing information stored in the study and its results. \nTo generate a surrogate we use MatCal's :class:`~matcal.core.surrogates.SurrogateGenerator`.\nWe construct a generator by passing in the study we just completed.\nIf we wanted to we could alter some of the surrogate generator's settings\nby evoking :meth:`~matcal.core.surrogates.SurrogateGenerator.set_surrogate_details`, \nbut we pass arguments for the surrogate generator directly through its initialization.\nWe then generate our surrogate by \ncalling :meth:`~matcal.core.surrogates.SurrogateGenerator.generate` with \na filename we would like to save our surrogate to. \nThe method then returns the surrogate, and saves a copy of it to \nthe filename we passed with a \".joblib\" file extension. \n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "surrogate_generator = mc.SurrogateGenerator(sampling_study, interpolation_field='time',\n                                            regressor_type=\"Gaussian Process\", \n                                            n_restarts_optimizer=20, \n                                            alpha=1e-5, \n                                            normalize_y=True)\nsurrogate_generator.set_PCA_details(decomp_var=4)\nsurrogate = surrogate_generator.generate(\"layered_metal_bc_surrogate\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To avoid rerunning a sampling study when debugging the surrogate generator, \nit is recommended that one pass a :class:`~matcal.core.study_base.StudyResults`\nwith the relevant information from the sampling study rather than rerun the whole \nstudy when that is not required. This information is stored in the \"final_results.joblib\"\nfile generated by the sampling study. This information can be loaded by calling \n:func:`~matcal.core.serializer_wrapper.matcal_load`.\n\nWhile the surrogate is being trained, \nthe generator will report the testing and training scores for each QOI \nthe surrogate was requested to predict. The best score for any test is 1, \nwith poorer scores less than 1. The training score represents how well the \nsurrogate performs on the data it was trained with, and the test score\nindicates how well the surrogate performs on data it was not trained on. \nIdeally both of these scores should be greater than .95. If either score is \nmuch below that then the surrogate will likely have poor applicability. \n\n<div class=\"alert alert-danger\"><h4>Warning</h4><p>These scores represent how well the surrogates predict the PCA mode amplitudes\n   not the actual curves. Therefore, adequate test scores may not be a direct \n   indication of accuracy for predicting the response in the original space.\n   If there are too many modes, the score may be low, but the predictions may be \n   adequate. If there are too few modes, the score may be high, but the predictions\n   may be poor.\n   Always verify surrogate quality as we do below.</p></div>\n\nEven with relatively high scores, the result will likely be a decent approximation \nof the desired response. This can still be useful if the actual models are very expensive\nand you need a less expensive model to determine areas in the parameter space \nthe produce desired results. A focused study can then be performed \nwith the full model after using the surrogate model to identify regions of interest\nin the parameter space.\n\nOne important case is when the training score is much higher than the testing score. \nThis is an indication that the surrogate is overfitting to its training data. \nThis means that predictions outside of the training data set are likely to be very \ninaccurate. If this is the case there can be a couple of common causes:\n\n#. The source data is poor, try increasing the number of prediction points and the \n   number of samples run. \n\n#. There is insufficient data for the underlying predictor. Increase the number of\n   samples used during sampling and/or reduce the complexity level of the predictor. \n\n#. There is a poor corelation between the QOIs and the parameters. Examine the\n   results of the sensitivity study to gain a better understanding of how the QOIs \n   and the parameters relate to each other and then try again. \n\n#. Trying to predict QOI that change by several orders of magnitude (even going from 1 to near 0).\n   In these cases it is better to calibrate to the natural log of these values. This can be \n   done using the :meth:`~matcal.core.surrogates.SurrogateGenerator.set_fields_to_log_scale`\n   method of the surrogate generator. \n\nThe scores are output in the log files and standard output, but can \nalso be accessed as properties under the surrogate after \nit has been produced. We print the scores below \nfor this surrogate.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print('Train scores:\\n', surrogate.scores['train'])\nprint('Test scores:\\n', surrogate.scores['test'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Both the test scores and the training scores indicate the surrogates are well\ntrained and can be used to predict our responses. \n\nNow we use the surrogate to make predictions of the model \nresponses. \nTo do so, we pass in an array of parameters that we want evaluated.\nThe surrogate will return a dictionary of predictions.  \nThe order of the parameters is the same order that they were \npassed into the the parameter collection or study, but this can be verified by \ncalling :meth:`~matcal.core.surrogates.MatCalMultiModalPCASurrogate.parameter_order`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "H = 10\nT_inf = 600\nT_air = 400\n\nprediction = surrogate([H, T_inf, T_air])\n\nimport matplotlib.pyplot as plt\nplt.close('all')\nplt.figure(constrained_layout=True)\nplt.plot(prediction['time'], prediction['TC_top'].flatten(), label=\"top\")\nplt.plot(prediction['time'], prediction['TC_bottom'].flatten(), label=\"bottom\")\nplt.xlabel(\"time (s)\")\nplt.ylabel(\"temperature (K)\")\nplt.legend()\nplt.title(\"Single Surrogate Prediction\")\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Multiple sets of parameters can be evaluated simultaneously. \nEach field in the returned prediction will have a number of rows equal to \nthe number of passed parameter sets.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "H = 10\nT_inf = 600\nT_air = 400\n\nH2 = 20\nT_inf2 = 815\nT_air2 = 634\n\nprediction2 = surrogate([[H, T_inf, T_air], [H2, T_inf2, T_air2]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can also run the actual model for these parameters for comparison \nto the surrogate. Doing this step is recommended \nwhen determining if a surrogate is adequate for use in calibration or \nother studies. We do so using the \n:class:`~matcal.core.parameter_studies.ParameterStudy`. \n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "param_study = mc.ParameterStudy(conv_heat_transfer_coeff, far_field_temperature,\n                                 air_temperature)\nparam_study.add_evaluation_set(my_hifi_model, my_objective)\nparam_study.set_core_limit(16)\nparam_study.add_parameter_evaluation(H=10, T_inf=600, T_air=400)\nparam_study.add_parameter_evaluation(H=20, T_inf=815, T_air=634)\nresults = param_study.launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With both the finite element model results \nand the surrogate model results obtained, we can \nplot them together for comparison.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fe_data1 = results.simulation_history[my_hifi_model.name][\"matcal_default_state\"][0]\nfe_data2 = results.simulation_history[my_hifi_model.name][\"matcal_default_state\"][1]\n\n\nplt.figure(constrained_layout=True)\nplt.plot(prediction2['time'], prediction2['TC_top'][0,:], '.', label=\"top prediction 1\", \n         color='tab:blue')\nplt.plot(prediction2['time'], prediction2['TC_top'][1,:], '.', label=\"top prediction 2\", \n         color='tab:orange')\nplt.plot(prediction2['time'], prediction2['TC_bottom'][0,:], '.', label=\"bottom prediction 1\", \n         color='tab:green')\nplt.plot(prediction2['time'], prediction2['TC_bottom'][1,:], '.', label=\"bottom prediction 2\", \n         color='tab:red')\n\nplt.plot(fe_data1['time'], fe_data1['TC_top'], label=\"top FE results 1\", \n         color='cornflowerblue')\nplt.plot(fe_data2['time'], fe_data2['TC_top'], label=\"top FE results 2\", \n         color='orange')\nplt.plot(fe_data1['time'], fe_data1['TC_bottom'], label=\"bottom FE results 1\", \n         color='lightgreen')\nplt.plot(fe_data2['time'], fe_data2['TC_bottom'], label=\"bottom FE results 2\", \n         color='orangered')\nplt.xlabel(\"time (s)\")\nplt.ylabel(\"temperature (K)\")\n\nplt.legend(ncols=2)\nplt.title(\"Multiple Surrogate Predictions\")\n\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Similarly, we can plot the surrogate model error. First, \nwe interpolate the surrogate results to the finite element model \ntimes. Next, we calculate and plot the absolute error \nfor each prediction.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "interp_prediction_top1 = np.interp(fe_data1['time'], prediction2['time'], \n                                     prediction2['TC_top'][0,:])\ninterp_prediction_top2 = np.interp(fe_data2['time'], prediction2['time'], \n                                     prediction2['TC_top'][1,:])\n\ninterp_prediction_bot1 = np.interp(fe_data1['time'], prediction2['time'], \n                                     prediction2['TC_bottom'][0,:])\ninterp_prediction_bot2 = np.interp(fe_data2['time'], prediction2['time'], \n                                     prediction2['TC_bottom'][1,:])\n\nplt.figure(constrained_layout=True)\nplt.plot(fe_data1['time'], interp_prediction_top1-fe_data1['TC_top'], \n         label=\"top TC error 1\", \n         color='tab:blue')\nplt.plot(fe_data2['time'], interp_prediction_top2-fe_data2['TC_top'], \n         label=\"top TC error 2\", \n         color='tab:orange')\nplt.plot(fe_data1['time'], interp_prediction_bot1-fe_data1['TC_bottom'], \n         label=\"bottom TC error 1\", \n         color='tab:green')\nplt.plot(fe_data2['time'], interp_prediction_bot2-fe_data2['TC_bottom'], \n         label=\"bottom TC error 2\", \n         color='tab:red')\nplt.xlabel(\"time (s)\")\nplt.ylabel(\"temperature error (K)\")\n\nplt.legend(ncols=2)\nplt.title(\"Multiple Surrogate Predictions\")\n\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "These results show that the surrogates predict the response fairly well. \nMost of the error is below 10 K throughout the entire history which is just a few \npercent for the curves.  The second prediction for the bottom thermal couple\nhas the worst surrogate prediction late in the time history. This could potentially\nbe improved with more modes and more training samples.\n\nIf needed, we can load this surrogate again for future use by constructing a \n:class:`~matcal.core.surrogates.MatCalMultiModalPCASurrogate`, with the saved filename\ncreated during the surrogate's generation. \n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from matcal.core.surrogates import load_matcal_surrogate\nloaded_surrogate = load_matcal_surrogate(\"layered_metal_bc_surrogate.joblib\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lastly, the surrogate can be investigated in an interactive manner using \nMatCal's interactive tools. To do so, use the command line call:\n```python\ninteractive_matcal -s <path_to_surrogate_save_file>\n```\nThis command will launch a browser window in which you can investigate your surrogate.\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}