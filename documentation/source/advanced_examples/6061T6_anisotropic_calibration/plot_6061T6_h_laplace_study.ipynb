{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# 6061T6 aluminum calibration uncertainty quantification\nIn this example, we will use MatCal's :class:`~matcal.core.parameter_studies.LaplaceStudy`\nto estimate the parameter uncertainty for the calibration. \n\nThis uncertainty quantification study differs from \nthe one in `304L stainless steel viscoplastic calibration uncertainty quantification`\nbecause many of the parameters are directly correlated to other parameters in the \nmodel. Specifically, the temperature and anisotropy parameters, are \nmultipliers of the yield stress and Voce hardening parameters. As a result,\nwe will assume all parameter uncertainty can be attributed to\nthe yield stress and Voce hardening parameters alone. This will significantly \nreduce the cost of the finite difference calculations needed \nfor the :class:`~matcal.core.parameter_studies.LaplaceStudy` and ensure robustness \nof the method. \n\nWe want the uncertainty \nin these three parameters to account for all uncertainty in the room temperature experiments, \nso we include these models in the uncertainty study. \n\n<div class=\"alert alert-danger\"><h4>Warning</h4><p>The LaplaceStudy is still in development and may not accurately attribute uncertainty to \n    to the parameters. Always verify results before use.</p></div>\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>Useful Documentation links:\n\n    #. `Uniaxial Tension Models`\n    #. `Top Hat Shear Model`\n    #. :class:`~matcal.core.parameter_studies.LaplaceStudy`</p></div>\nTo begin, we import the tools we need for this study.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from matcal import *\nfrom matcal.sandia.computing_platforms import is_sandia_cluster, get_sandia_computing_platform\n\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nplt.rc('text', usetex=True)\nplt.rc('font', family='serif')\nplt.rc('font', size=12)\nfigsize = (4,3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we import the data and remove\nany uncalibrated data from the \n:class:`~matcal.core.data.DataCollection` objects.\nWe do this in place of weighting, because zeros in the residuals \ncan cause scaling and conditioning issues in the linear algebra\nrequired for the study.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "tension_data_collection = BatchDataImporter(\"ductile_failure_aluminum_6061_data/\" \n                                              \"uniaxial_tension/processed_data/\"\n                                              \"cleaned_[CANM]*.csv\",).batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For the room temperature tension data, \nwe remove data in the elastic region and in regions of unloading \nto match what was included in the objective for the calibration.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "down_selected_tension_data = DataCollection(\"down selected data\")\nfor state in tension_data_collection.keys():\n    for index, data in enumerate(tension_data_collection[state]):\n        stresses = data[\"engineering_stress\"]\n        strains = data[\"engineering_strain\"]    \n        peak_index = np.argmax(stresses)\n        peak_strain = strains[peak_index]\n        peak_stress = stresses[peak_index]\n        data_to_keep = (((strains>peak_strain) & (stresses > 0.89*peak_stress)) | \n                        (strains>0.005) & (strains < peak_strain))\n        down_selected_tension_data.add(data[data_to_keep])\n\ndown_selected_tension_data = scale_data_collection(down_selected_tension_data, \n                                                   \"engineering_stress\", 1000)\ndown_selected_tension_data.remove_field(\"time\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With the down-selected tension data created, \nwe create the :class:`~matcal.sierra.models.RoundUniaxialTensionModel`\nas we did in `6061T6 aluminum calibration with anisotropic yield`, \nand add the :class:`~matcal.core.data.DataCollection` that we created\nas the model boundary condition data.   \n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "material_filename = \"hill_plasticity_temperature_dependent.inc\"\nmaterial_model = \"hill_plasticity\"\nmaterial_name = \"ductile_failure_6061T6\"\nsierra_material = Material(material_name, material_filename, material_model)\n\ngauge_radius = 0.125\nelement_size = gauge_radius/8\ngeo_params = {\"extensometer_length\": 1.0,\n              \"gauge_length\": 1.25,\n              \"gauge_radius\": gauge_radius,\n              \"grip_radius\": 0.25,\n              \"total_length\": 4,\n              \"fillet_radius\": 0.188,\n              \"taper\": 0.0015,\n              \"necking_region\":0.375,\n              \"element_size\": element_size,\n              \"mesh_method\":3,\n              \"grip_contact_length\":1}\n\ntension_model = RoundUniaxialTensionModel(sierra_material, **geo_params)            \ntension_model.set_name(\"tension_model\")\ntension_model.add_boundary_condition_data(down_selected_tension_data)\ntension_model.set_allowable_load_drop_factor(0.70)\ntension_model.set_boundary_condition_scale_factor(1.5)\n\nmy_wcid = \"fy220213\"\nif is_sandia_cluster():\n  tension_model.run_in_queue(my_wcid, 1)\n  tension_model.continue_when_simulation_fails()\n  platform = get_sandia_computing_platform()\n  num_cores = platform.get_processors_per_node()\nelse:\n  num_cores = 8\ntension_model.set_number_of_cores(num_cores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Similarly, we import the top hat data and \ndown select the data of interest for the residuals.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "top_hat_data_collection = BatchDataImporter(\"ductile_failure_aluminum_6061_data/\" \n                                              \"top_hat_shear/processed_data/cleaned_*.csv\").batch\nfor state, state_data_list in top_hat_data_collection.items():\n    for index, data in enumerate(state_data_list):\n        max_load_arg = np.argmax(data[\"load\"])\n        # This slicing procedure removes the data after peak load \n        # and before displacements of 0.005\".\n        data = data[data[\"time\"] < data[\"time\"][max_load_arg]]\n        data = data[data[\"displacement\"] > 0.005]\n        # This one removes the data after a displacement of 0.02\"\n        # and reassigns the modified data to the \n        # DataCollection\n        top_hat_data_collection[state][index] = data[data[\"displacement\"] < 0.02]\ntop_hat_data_collection.remove_field(\"time\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With the data prepared, \nwe can build the model as we did \nin the previous example `6061T6 aluminum calibration with anisotropic yield`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "top_hat_geo_params = {\"total_height\":1.25,\n        \"base_height\":0.75,\n        \"trapezoid_angle\": 10.0,\n        \"top_width\": 0.417*2,\n        \"base_width\": 1.625, \n        \"base_bottom_height\": (0.75-0.425),\n        \"thickness\":0.375, \n        \"external_radius\": 0.05,\n        \"internal_radius\": 0.05,\n        \"hole_height\": 0.3,\n        \"lower_radius_center_width\":0.390*2,\n        \"localization_region_scale\":0.0,\n        \"element_size\":0.005, \n        \"numsplits\":1}\n\ntop_hat_model = TopHatShearModel(sierra_material, **top_hat_geo_params)\ntop_hat_model.set_name('top_hat_shear')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we set its allowable load drop factor \nand provide boundary condition data. \n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "top_hat_model.set_allowable_load_drop_factor(0.05)\ntop_hat_model.add_boundary_condition_data(top_hat_data_collection)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lastly, we setup the platform information \nfor running the model. \n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "top_hat_model.set_number_of_cores(num_cores*2)\nif is_sandia_cluster():\n  top_hat_model.run_in_queue(my_wcid, 1)\n  top_hat_model.continue_when_simulation_fails()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now create the objectives for the \ncalibration. \nBoth models are compared to the data \nusing a :class:`~matcal.core.objective.CurveBasedInterpolatedObjective`. \nThe tension specimen is calibrated to the engineering stress/strain data\nand the top hat specimen is calibrated to the load-displacement data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "tension_objective = CurveBasedInterpolatedObjective(\"engineering_strain\", \"engineering_stress\")\ntension_objective.set_name(\"engineering_stress_strain_obj\")\ntop_hat_objective = CurveBasedInterpolatedObjective(\"displacement\", \"load\")\ntop_hat_objective.set_name(\"load_displacement_obj\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now create our parameters for the\nstudy. The study parameters are the ``yield_stress``, ``hardening`` and \n``b`` parameters from \n`6061T6 aluminum calibration with anisotropic yield` with \ntheir current value set to their calibration values.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "RT_calibrated_params = matcal_load(\"anisotropy_parameters.serialized\")\nyield_stress = Parameter(\"yield_stress\", 15, 50, \n        RT_calibrated_params.pop(\"yield_stress\"))\nhardening = Parameter(\"hardening\", 0, 60, \n        RT_calibrated_params.pop(\"hardening\"))\nb = Parameter(\"b\", 10, 40,\n        RT_calibrated_params.pop(\"b\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To simplify setting up the laplace study, \nwe put all the parameters in a :class:`~matcal.core.parameters.ParameterCollection`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "pc = ParameterCollection(\"uncertain_params\", yield_stress, hardening, b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We also need the anisotropy so we store those parameters with the \ncurrent value equal to the calibrated parameter values from the calibration step.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "R22 = Parameter(\"R22\", 0.8, 1.15, \n        RT_calibrated_params[\"R22\"])\nR33 = Parameter(\"R33\", 0.8, 1.15, \n        RT_calibrated_params[\"R33\"])\nR12 = Parameter(\"R12\", 0.8, 1.15, \n        RT_calibrated_params[\"R12\"])\nR23 = Parameter(\"R23\", 0.8, 1.15, \n        RT_calibrated_params[\"R23\"])\nR31 = Parameter(\"R31\", 0.8, 1.15,\n        RT_calibrated_params[\"R31\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The anisotropy parameters and temperature dependence parameters from \n`6061T6 aluminum temperature dependent calibration`\nwill be added as model constants because they are \nbeing treated as deterministic and are still required for the models.        \nThey are added for the two models for this study.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "high_temp_calibrated_params = matcal_load(\"temperature_dependent_parameters.serialized\")\ntension_model.add_constants(**high_temp_calibrated_params,\n                            **RT_calibrated_params)\ntop_hat_model.add_constants(**high_temp_calibrated_params,\n                            **RT_calibrated_params)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can create our laplace study\nand add our two evaluation sets. \n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "laplace_study = LaplaceStudy(pc)\nlaplace_study.set_parameter_center(**pc.get_current_value_dict())\nlaplace_study.set_working_directory(\"laplace_study\", remove_existing=True)\nlaplace_study.set_core_limit(250)\nlaplace_study.add_evaluation_set(tension_model, tension_objective, down_selected_tension_data)\nlaplace_study.add_evaluation_set(top_hat_model, top_hat_objective, top_hat_data_collection)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Laplace study specific options include \n:meth:`~matcal.core.parameter_studies.LaplaceStudy.set_step_size` to \nset the finite difference step size and \n:meth:`~matcal.core.parameter_studies.LaplaceStudy.set_noise_estimate`\nfor setting the estimated amount of noise in the data. \nWe set the finite difference step size to one order of magnitude less than  \nthe default. Results are likely sensitive to \nthis value for practical problems, and re-running the study \nwith different values may be required.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "laplace_study.set_step_size(1e-4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For this study type, \nproviding an inaccurate noise estimate can result in unreasonable solutions. \n\n<div class=\"alert alert-danger\"><h4>Warning</h4><p>Appropriately handling the noise estimate is an\n   active area of research. If attempted, some iteration may be required to \n   find an valid estimate for noise. \n   This can be done by running the study once to evaluate the model response and then re-running\n   the study as a restart after changing the noise estimate or by calling\n   :meth:`~matcal.core.parameter_studies.LaplaceStudy.update_laplace_estimate`.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "laplace_study.set_noise_estimate(1e-2)\nresults = laplace_study.launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "After the study completes, there are two results of concern:\n #. The estimated parameter covariance -  calculated directly from the residual magnitude \n    and the gradients of the residuals w.r.t. the parameters. \n #. The fitted parameter covariance - an optimized covariance that ensures the \n    the covariance of the parameters is representative of the uncertainty due to \n    model form error. This corrects the estimated parameter covariance \n    using the objective described in `Laplace Approximation: Error Attributed to Model Error` \n\nWe print both of these values below and save the results to be used in the next \nstep of this example.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"Initial covariance estimate:\\n\", results.estimated_parameter_covariance)\nprint(\"Calibrated covariance estimate:\\n\", results.fitted_parameter_covariance)\nmatcal_save(\"laplace_study_results.joblib\", results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As noted above, the results can be sensitive to the estimated noise. To illustrate this point, \nwe re-run the study results processing with updated noise estimates and print the results. \nBefore updating the results, we save the previous\nresults as copy of themselves because the update just updates the values on the results \nobject.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import copy\nresults = copy.deepcopy(results)\n\nresults_high_noise = laplace_study.update_laplace_estimate(1e-1)\nresults_high_noise = copy.deepcopy(results_high_noise)\n\nprint(\"Initial covariance estimate noise set to 1e-2:\\n\", results.estimated_parameter_covariance)\nprint(\"Calibrated covariance estimate noise set to 1e-2:\\n\", \n      results.fitted_parameter_covariance)\n\nprint(\"Initial covariance estimate noise set to 1e-1:\\n\", results_high_noise.estimated_parameter_covariance)\nprint(\"Calibrated covariance estimate noise set to 1e-1:\\n\", \n      results_high_noise.fitted_parameter_covariance)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note the difference in the result.\nThis highlights the sensitivity of the method to the noise estimate. Some iteration may be\nrequired to obtain a useful result.\n\nNext, we sample the multivariate normal provided by the study covariance \nand calibrated values as the mean and visualize the results using seaborn's\nKDE pair plot\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "num_samples=5000\nuncertain_param_sets = sample_multivariate_normal(num_samples, \n                                                  results.mean.to_list(),\n                                                  results.fitted_parameter_covariance, \n                                                  12345, \n                                                  pc.get_item_names())\nimport seaborn as sns\nimport pandas as pd\nsns.pairplot(data=pd.DataFrame(uncertain_param_sets), kind=\"kde\" )\nplt.show()\n# From this plot, we can see the uncertainty is considerably overestimated\n# and could result in unphysical values of the parameters. This method is still \n# work in progress for models with significant model form error."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}