{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# 304L stainless steel viscoplastic uncertainty quantification validation\nIn this example, we will use MatCal's :class:`~matcal.core.parameter_studies.ParameterStudy`\nto validate the estimated parameter uncertainty for the calibration. \nWe do this by generating samples from the fitted covariance from \n`304L stainless steel viscoplastic calibration uncertainty quantification` and \nrunning the calibrated models with these samples. Then the \nmodel results are compared to the data to see how well the sampled parameter \nsets allow the models to represent the data uncertainty. \n\n<div class=\"alert alert-info\"><h4>Note</h4><p>Useful Documentation links:\n\n    #. `Uniaxial Tension Models`\n    #. :class:`~matcal.core.models.PythonModel`\n    #. :func:`~matcal.core.parameter_studies.sample_multivariate_normal`</p></div>\n\nTo begin, we reuse the data import, model preparation \nand objective specification for the tension model and rate \nmodels from `304L stainless steel viscoplastic calibration uncertainty quantification`.    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nimport matplotlib.pyplot as plt\nfrom matcal import *\n\nplt.rc('text', usetex=True)\nplt.rc('font', family='serif')\nplt.rc('font', size=12)\nfigsize = (4,3)\n\ntension_data = BatchDataImporter(\"ductile_failure_ASTME8_304L_data/*.dat\", \n                                    file_type=\"csv\", \n                                    fixed_states={\"displacement_rate\":2e-4, \n                                                  \"temperature\":530}).batch\n\ntension_data = scale_data_collection(tension_data, \"engineering_stress\", 1000)\ntension_data.remove_field(\"time\")\n\ndown_selected_data = DataCollection(\"down selected data\")\nfor state in tension_data.keys():\n   for index, data in enumerate(tension_data[state]):\n      down_selected_data.add(data[(data[\"engineering_stress\"] > 36000) &\n                                  (data[\"engineering_strain\"] < 0.75)])\n\nrate_data_collection = matcal_load(\"rate_data.joblib\")\n\ncalibrated_params = matcal_load(\"voce_calibration_results.serialized\")\n\nY_0 = Parameter(\"Y_0\", 20, 60, \n                calibrated_params[\"Y_0\"])\nA = Parameter(\"A\", 100, 400, \n              calibrated_params[\"A\"])\nb = Parameter(\"b\", 0, 3, \n              calibrated_params[\"b\"])\nC = Parameter(\"C\", -3, -0.5, calibrated_params[\"C\"])\nX = Parameter(\"X\", 0.50, 1.75, 1.0)\nparams = ParameterCollection(\"laplace params\", Y_0, A, b, C)\n\ndef JC_rate_dependence_model(Y_0, A, b, C, X, ref_strain_rate, rate, **kwargs):\n    yield_stresses = np.atleast_1d(Y_0*X*(1+10**C*np.log(rate/ref_strain_rate)))\n    yield_stresses[np.atleast_1d(rate) < ref_strain_rate] = Y_0\n    return {\"yield\":yield_stresses}\n\nrate_model = PythonModel(JC_rate_dependence_model)\nrate_model.set_name(\"python_rate_model\")\n\nmaterial_name = \"304L_viscoplastic\"\nmaterial_filename = \"304L_viscoplastic_voce_hardening.inc\"\nsierra_material = Material(material_name, material_filename,\n                            \"j2_plasticity\")\n\ngeo_params = {\"extensometer_length\": 0.75,\n               \"gauge_length\": 1.25, \n               \"gauge_radius\": 0.125, \n               \"grip_radius\": 0.25, \n               \"total_length\": 4, \n               \"fillet_radius\": 0.188,\n               \"taper\": 0.0015,\n               \"necking_region\":0.375,\n               \"element_size\": 0.01,\n               \"mesh_method\":3, \n               \"grip_contact_length\":1}\n\nastme8_model = RoundUniaxialTensionModel(sierra_material, **geo_params)            \nastme8_model.add_boundary_condition_data(tension_data)       \n\nfrom site_matcal.sandia.computing_platforms import is_sandia_cluster, get_sandia_computing_platform\nfrom site_matcal.sandia.tests.utilities import MATCAL_WCID\n\ncores_per_node = 24\nif is_sandia_cluster():\n    platform = get_sandia_computing_platform()\n    cores_per_node = platform.processors_per_node\n\nastme8_model.set_number_of_cores(cores_per_node)\nif is_sandia_cluster():       \n    astme8_model.run_in_queue(MATCAL_WCID, 1)\n    astme8_model.continue_when_simulation_fails()\nastme8_model.set_allowable_load_drop_factor(0.45)\nastme8_model.set_name(\"ASTME8_tension_model\")\nastme8_model.add_constants(ref_strain_rate=1e-5)\n\nX_calibrated = calibrated_params.pop(\"X\")\nrate_model.add_constants(ref_strain_rate=1e-5, X=X_calibrated)\nastme8_model.add_constants(ref_strain_rate=1e-5)\n\nrate_objective = Objective(\"yield\")\nastme8_objective = CurveBasedInterpolatedObjective(\"engineering_strain\", \"engineering_stress\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With the models, data, and objectives created, \nwe import the :class:`~matcal.core.parameter_studies.LaplaceStudy` results from the previous step.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "laplace_covariance = matcal_load(\"laplace_study_covariance.joblib\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we can sample\nthe calculated parameter distribution using \n:func:`~matcal.core.parameter_studies.sample_multivariate_normal` and evaluate \nthe parameter uncertainty as desired. \n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "num_samples=40\nmean = [calibrated_params[\"Y_0\"], calibrated_params[\"A\"],\n         calibrated_params[\"b\"], calibrated_params[\"C\"]]\nuncertain_param_sets = sample_multivariate_normal(num_samples, \n                                                  mean,\n                                                  laplace_covariance, \n                                                  12345, \n                                                  params.get_item_names())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We save the parameter samples to be used or plotted later.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "matcal_save(\"laplace_uq_validation_results.joblib\", uncertain_param_sets)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we set up a study so we can \nvisualize the results by pushing the samples back through the models.\nWe do so using a MatCal :class:`~matcal.core.parameter_studies.ParameterStudy`.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "param_study = ParameterStudy(Y_0, A, b, C)\nparam_study.add_evaluation_set(astme8_model, astme8_objective, tension_data)\nparam_study.add_evaluation_set(rate_model, rate_objective, rate_data_collection)\nparam_study.set_core_limit(250)\nsampling_dir = \"UQ_sampling_study\"\nparam_study.set_working_directory(sampling_dir, remove_existing=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we add parameter evaluations for each of the samples. \nWe do so by organizing the data using Python's\n``zip`` function and then loop over the result\nto add each parameter set sample to the study.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>We add error catching to the addition of each parameter \n   evaluation. There is a chance that parameters could be \n   generated outside of our original bounds and we want the study to complete.\n   If this error is caught, we will see it in the MatCal output \n   and know changes are needed. However, some results will still be output\n   and can be of use.</p></div>\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "params_to_evaluate = zip(uncertain_param_sets[\"Y_0\"], uncertain_param_sets[\"A\"],\n                         uncertain_param_sets[\"b\"], uncertain_param_sets[\"C\"])\n\nfor Y_0, A_eval, b_eval, C_eval in params_to_evaluate:\n    try:\n      param_study.add_parameter_evaluation(Y_0=Y_0, A=A_eval, b=b_eval, C=C_eval)\n      print(f\"Running evaluation with Y_0={Y_0}, A={A_eval}, b={b_eval}, and \"\n          f\"C={C_eval}.\")\n                               \n    except ValueError:\n       print(f\"Skipping evaluation with Y={Y_0}, A={A_eval}, b={b_eval}, and \"\n            f\"C={C_eval}. Parameters out of range.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we launch the study and plot the results.\nOnce again, we use plotting functions from \nthe previous examples to simplify the plotting processes.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "param_study_results = param_study.launch()\nastme_results = param_study_results.simulation_history[astme8_model.name]\nrate_results = param_study_results.simulation_history[rate_model.name]\n\ndef compare_data_and_model(data, model_responses, indep_var, dep_var, \n                           plt_func=plt.plot, fig_label=\"\"):\n  fig = plt.figure(fig_label, constrained_layout=True, figsize=figsize)\n  data.plot(indep_var, dep_var, plot_function=plt_func, ms=3, labels=\"data\", \n            figure=fig, marker='o', linestyle='-', color=\"#bdbdbd\", show=False)\n  model_responses.plot(indep_var, dep_var, plot_function=plt_func,labels=\"models\", \n                      figure=fig, linestyle='-', alpha=0.5)\n  plt.xlabel(\"Engineering Strain (.)\")\n  plt.ylabel(\"Engineering Stress (psi)\")\n  \n\ncompare_data_and_model(tension_data, astme_results, \n                       \"engineering_strain\", \"engineering_stress\", \n                       fig_label=\"tension model\")\n\ndef make_single_plot(data_collection, state, cur_idx, label, \n                     color, marker, **kwargs):\n    data = data_collection[state][cur_idx]\n    plt.semilogx(state[\"rate\"], data[\"yield\"][0],\n                marker=marker, label=label, color=color, \n                **kwargs)\n\ndef plot_dc_by_state(data_collection, label=None, color=None,\n                     marker='o', best_index=None, only_label_first=False, **kwargs):\n    for state in data_collection:\n        if best_index is None:\n            for idx, data in enumerate(data_collection[state]):\n                make_single_plot(data_collection, state, idx, label, \n                                 color, marker, **kwargs)\n                if ((color is not None and label is not None) or\n                    only_label_first):\n                    label = None\n        else:\n            make_single_plot(data_collection, state, best_index, label, \n                             color, marker, **kwargs)\n    plt.xlabel(\"engineering strain rate (1/s)\")\n    plt.ylabel(\"yield stress (ksi)\")\n\nplt.figure(constrained_layout=True, figsize=figsize)\nplot_dc_by_state(rate_data_collection, label='experiments', \n                 color=\"k\", markersize=10)\nplot_dc_by_state(rate_results, label='rate model', marker='x',\n                 only_label_first=True)\nplt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "These figure show the model results from the 40 samples. \nFor the tension model, the results appear to be good estimate of parameter \nuncertainty. The simulations encapsulate all data, without exhibiting \ntoo much variability. While the python rate dependence model results do not \ncompletely encapsulates all \ndata, the results seem to be an adequate measure of overall uncertainty.\nsphinx_gallery_thumbnail_number = 3\n\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}