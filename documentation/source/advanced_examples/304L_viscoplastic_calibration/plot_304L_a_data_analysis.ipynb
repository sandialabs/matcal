{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# 304L bar data analysis\nIn this example, we analyze the tension data for 304L at several strain rates \nfrom :cite:p:`laser_weld_paper`. \nSince 304L material is known to exhibit rate dependence that is measurable\nwhen increasing strain rates an order of magnitude or more, this data \nset is a good data set to analyze for rate dependence. After analyzing the data, \nwe will then use MatCal tools to help chose a model for for the rate dependence.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>Useful Documentation links:\n\n    #. :class:`~matcal.core.data_importer.BatchDataImporter`\n    #. :meth:`~matcal.core.data.DataCollection.plot` \n    #. :func:`~matcal.core.data_analysis.determine_pt2_offset_yield`</p></div>\n\nFirst we import the python libraries we will use. For this example, we will use\nMatCal, NumPy and Matplotlib.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from matcal import *\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nplt.rc('text', usetex=True)\nplt.rc('font', family='serif')\nplt.rc('font', size=12)\nfigsize = (4,3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we import the data using the :class:`~matcal.core.data_importer.BatchDataImporter`.\nThese files have been preprocessed to include state information in each file, \nso that they can be imported with `engineering_strain_rate` and `temperature`\nstate variables pre-assigned to each experiment.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data = BatchDataImporter(\"ductile_failure_small_tension_data/*.csv\").batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that the data is imported, we create data structures that \nwill aid in plotting the yield stresses\nand stresses at 5 percent strain \nas a function of rate. \nWe look at these stresses to determine \nif both yield and hardening are rate dependent.\nSo for each experiment in the data set, \nwe save these values in our data structures.\nMatCal's :func:`~matcal.core.data_analysis.determine_pt2_offset_yield`\nfunction is useful here for extracting the 0.2% offset yield \nstress from engineering stress strain curves.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "yield_stresses = {0.0001:[],\n                  0.01:[],\n                  500.0:[],\n                  1800.0:[],\n                  3600.0:[]}\nfive_percent_strain_stresses = {0.0001:[],\n                  0.01:[],\n                  500.0:[],\n                  1800.0:[],\n                  3600.0:[]}\n\nfor state, data_sets in data.items():\n    for data in data_sets:\n        rate = state[\"engineering_strain_rate\"]\n        yield_pt = determine_pt2_offset_yield(data, 29e3)\n        yield_stresses[rate].append(yield_pt[1])\n        five_strain = np.interp(0.05, data[\"engineering_strain\"], \n                                data[\"engineering_stress\"])\n        five_percent_strain_stresses[rate].append(five_strain)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With the data organized as needed, we can \ncreate box blots of these values at each rate. \nThis will allow us to see how these values change\nfor each of the measured rates.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=figsize, constrained_layout=True)\nbp_yield=plt.boxplot(yield_stresses.values(), labels=yield_stresses.keys())\nplt.setp(bp_yield['boxes'], color='tab:blue')\nplt.xlabel(\"engineering strain rate (1/s)\")\nplt.ylabel(\"stress (ksi)\")\nbp_5 =plt.boxplot(five_percent_strain_stresses.values(), \n            labels=five_percent_strain_stresses.keys())\nplt.setp(bp_5['boxes'], color='tab:red')\nplt.legend([bp_yield[\"boxes\"][0], bp_5[\"boxes\"][0]], ['yield stress', \n                                                      'stress at 5\\% strain'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "From these plots, we can see that the material does exhibit rate \ndependence when the engineering strain rate changes several orders of magnitude.\nRate dependence in the material yield is clear. The stresses at five\npercent strain show that the material hardening is likely rate independent.\nThis is apparent because the stress increase at the different rates does not \nincrease at the stress at 5% strain as would be expected if the material \nhardening was also rate dependent. Instead it decreases. This decrease is likely \ndue to heating due to plastic work in the material at high rate.\n\nWe now plot just the yield data on a ``semilogx`` plot\nto visually assess the relationship between yield stress and strain rate. \nTwo commonly used strain rate dependent yield models for metals\ninclude the Johnson-Cook model (JC) and the Power-law Breakdown model (PLB).\nThe functional form for the JC rate dependence model is:\n\n .. math::\n\n   Y\\left(\\dot{\\epsilon}^p\\right) = Y_0\\left[1+C\\ln\\left(\\frac{\\dot{\\epsilon}^p}\n   {\\dot{\\epsilon}_0}\\right)\\right]\n\nwhere $Y_0$ is the rate independent yield stress,\n$C$ is a calibration constant, $\\dot{\\epsilon}^p$\nis the material plastic strain rate, and $\\dot{\\epsilon}_0$ is a reference \nstrain rate under which the material is rate independent. \nThe functional form for the PLB rate dependence model is:\n\n\\begin{align}Y\\left(\\dot{\\epsilon}^p\\right) = Y_0\\left[1+\\text{sinh}^{-1}\\left(\\left(\n  \\frac{\\dot{\\epsilon}^p}{g}\\right)^{(1/m)}\\right)\\right]\\end{align}\n\nwhere $Y_0$ is the rate independent yield stress, and\n$g$ and $b$ are a calibration constants. \n\nAs a function of strain rate, the JC model is linear in a ``semilogx``\nplot while the PLB can exhibit curvature. To see how these data looks and\nif one of these model are clearly more appropriate, \nwe plot the data on a ``semilogx``\nFirst we put the data into a MatCal :class:`matcal.core.data.Data` class.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "yield_dc = DataCollection(\"yeild vs rate\")\nfor rate in yield_stresses:\n    rate_state = State(f\"rate_{rate}\", rate=rate)\n    for yield_stress in yield_stresses[rate]:\n        data = convert_dictionary_to_data({\"yield\":[yield_stress]})\n        data.set_state(rate_state)\n        yield_dc.add(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we plot the data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=figsize, constrained_layout=True)\ndef plot_dc_by_state(data_collection, label=None, color=None, best_index=None):\n    for state in data_collection:\n        if best_index is None:\n            for idx, data in enumerate(data_collection[state]):\n                plt.semilogx(state[\"rate\"], data[\"yield\"][0],\n                            marker='o', label=label, color=color)\n                if color is not None and label is not None:\n                    label = \"_\"+label\n        else:\n            data = data_collection[state][best_index]\n            plt.semilogx(state[\"rate\"], data[\"yield\"][0],\n                            marker='o', label=label, color=color)\n            if color is not None and label is not None:\n                label = \"_\"+label\n                \n    plt.xlabel(\"engineering strain rate (1/s)\")\n    plt.ylabel(\"yield stress (ksi)\")\nplot_dc_by_state(yield_dc)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Upon inspection, it is not immediately clear which model will fit the \ndata better. This is likely due to the fact that\nthere is significant scatter at the different strain rates and there is \nno data in the intermediate strain rates. As a result, \nwe will use MatCal tools to help decide which model we should choose\nbased on these data.\n\nTo begin, we calibrate each python model to these data.\nWe already have our data, so we need to create models that \ncan predict the trend in the data.\nWe use MatCal's :class:`~matcal.core.models.PythonModel` to \nimplement the models using python functions.  \nThese two models are defined below.\n\nFirst, we define the JC model python function.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def jc_rate_dependence_model(Y_0, C, ref_strain_rate, rate):\n    yield_stresses = np.atleast_1d(Y_0*(1+C*np.log(rate/ref_strain_rate)))\n    yield_stresses[np.atleast_1d(rate) < ref_strain_rate] = Y_0\n    return {\"yield\":yield_stresses}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Then we create the python model, name it \nand add the reference strain rate in as a state parameter as it \nwill be uncalibrated. \n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "jc_rate_model = PythonModel(jc_rate_dependence_model)\njc_rate_model.set_name(\"python_jc_rate_model\")\njc_rate_model.add_constants(ref_strain_rate=1e-5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next we define the PLB model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def plb_rate_dependence_model(Y_0, g_star, m, rate):\n    yield_stress = Y_0*(1+np.arcsinh((rate/10**(g_star))**(1/m)))\n    return {\"yield\":np.atleast_1d(yield_stress)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note that we are calibrating the constant $g$ on a log scale.\nWe create a parameter $g^*$, such that $g=10^{g*}$. This \nis needed because the model would otherwise appear insensitive to \n$g$ in MatCal studies. \n\nWith the function created, we now make the model and name it.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plb_rate_model = PythonModel(plb_rate_dependence_model)\nplb_rate_model.set_name(\"python_plb_rate_model\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we now define the parameters that will be calibrated for these model.\nBoth models will need to calibrate the rate independent yield stress, $Y_0$. \nThe bounds for this parameter are set based on what we observe in the low strain \nrate data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "Y_0 = Parameter(\"Y_0\", 20, 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The PLB model requires the two parameters $g_star$ and $m$. \nThe $g$ parameter is meant to represent a change in behavior for the \nrate dependence. It is based on experimental observations that show\nmaterials sensitivity to rate increase at high strain rates. In this model,\nit can be considered a reference rate above which the material becomes more rate\nsensitive. Since this is generally at higher rates for metals, we restrict this \nreference rate to be between 100 and 10000 per second. Any lower or higher, \nand the parameter will be used in an unintended fashion. The bounds for $m$\nare set based on our previous experience with the model for austenitic stainless steels.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "g_star = Parameter(\"g_star\", 2, 4)\nm = Parameter(\"m\", 2, 15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The only unique parameter for the JC model is the calibration parameter \n$C$ which we also set bounds for using our previous experience with the model\nfor metals.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "C = Parameter(\"C\", 0.001, 0.1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The last component needed for our calibrations is the objective. \nWe use a :class:`~matcal.core.objective.Objective` \nto fit our python models to the data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "obj = Objective(\"yield\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can setup our calibrations and save the results.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "jc_cal = GradientCalibrationStudy(Y_0, C)\njc_cal.add_evaluation_set(jc_rate_model, obj, yield_dc)\njc_cal.set_working_directory(\"jc\", remove_existing=True)\njc_cal_results = jc_cal.launch()\n\nplb_cal = GradientCalibrationStudy(Y_0, g_star, m)\nplb_cal.add_evaluation_set(plb_rate_model, obj, yield_dc)\nplb_cal.set_working_directory(\"plb\", remove_existing=True)\nplb_cal_results = plb_cal.launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With the calibrations complete, we plot the fits against the data and \nprint the best fit information. \n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "jc_best_idx = jc_cal_results.best_evaluation_index\njc_best_sim = jc_cal_results.simulation_history[jc_rate_model.name]\n\nplb_best_idx = plb_cal_results.best_evaluation_index\nplb_best_sim = plb_cal_results.simulation_history[plb_rate_model.name]\n\nplt.figure(figsize=figsize, constrained_layout=True)\nplot_dc_by_state(yield_dc, \"experiments\" , 'k')\nrates=np.logspace(-4,4,100)\nplt.semilogx(rates, jc_rate_dependence_model(**jc_cal_results.best.to_dict(),\n                                             ref_strain_rate=1e-5, \n                                             rate=rates)['yield'], label=\"JC model\")\nplot_dc_by_state(jc_best_sim, None, 'tab:blue', best_index=jc_best_idx)\nplt.semilogx(rates, plb_rate_dependence_model(**plb_cal_results.best.to_dict(),\n                                             rate=rates)['yield'], label=\"PLB model\")\nplot_dc_by_state(plb_best_sim, None, 'tab:orange', best_index=plb_best_idx)\nplt.legend()\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "From this plot, both models appear to represent the data well. \nLooking at the final total objective and parameters will reveal \nwhich model fits the data better and if there were any issues \nin the fitting process.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "jc_eval_set_name = f\"{jc_rate_model.name}:{obj.name}\"\njc_best_obj = jc_cal_results.best_total_objective\nprint(\"JC model best fit objective:\", jc_best_obj)\nprint(jc_cal_results.best.to_dict(),\"\\n\")\n\nplb_eval_set_name = f\"{plb_rate_model.name}:{obj.name}\"\nplb_best_obj = plb_cal_results.best_total_objective\nprint(\"PLB model best fit objective:\", plb_best_obj)\nprint(plb_cal_results.best.to_dict(),\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The objectives show that the PLB model provides a better fit to these\ndata. However, we can see in the fit that its parameter for $g_star$\nis hitting its upper bound. This is showing that the calibration is \nadjusting that parameter outside is intended use case for this model and \nis the first indication that we should use JC over PLB.\n\nTo look into this further, we will perform a sensitivity study on the objective\nwith respect to the parameters in both models. If the objective is not \nvery sensitive to the parameters, it can be an indication that the \nparameter is not very well defined by the given objective.\n\nWe start with the JC model. We need to redefine our\nparameters and add distributions to them to support the sensitivity \nstudy. We will assign them a ``uniform_uncertain`` distribution.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "Y_0 = Parameter(\"Y_0\", 20, 60, distribution=\"uniform_uncertain\")\nC = Parameter(\"C\", 0.001, 0.1, distribution=\"uniform_uncertain\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can create our :class:`~matcal.dakota.sensitivity_studies.LhsSensitivityStudy`\nand add our evaluation set.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>We update the metric function of the objective to \n   be the :class:`~matcal.core.objective.L2NormMetricFunction`.\n   This can provide a more interpretable result for sensitivity analyses\n   than the :class:`~matcal.core.objective.SumSquaresMetricFunction`.</p></div>\n\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sens = LhsSensitivityStudy(Y_0, C)\nobj.set_metric_function(L2NormMetricFunction())\nsens.add_evaluation_set(jc_rate_model, obj, yield_dc)\nsens.set_working_directory(\"jc_sens\", remove_existing=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We want to perform the study on the overall objective \nand to perform a Sobol index study. The Sobol index study\nprovides a global sensitivity of the models to the input parameters\nand are valid for nonlinear responses. \n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sens.use_overall_objective()\nsens.make_sobol_index_study()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Since the python model is inexpensive, \nwe take 2500 samples. For a problem with a more \ncomputationally expensive model, you should run many studies with increasing \nsamples until the Sobol indices converge.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "num_samples = 2500\nsens.set_number_of_samples(num_samples)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For python models, performance gains can be achieved by running \nthe evaluations in serial. Parallel evaluations require additional overhead\nthat can decrease performance when using inexpensive models such as a \n:class:`~matcal.core.models.PythonModel`. \n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "sens.run_in_serial()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now launch the study and save the results.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "jc_sens_results = sens.launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The sensitivity study for the PLB model is setup the same way.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "g_star = Parameter(\"g_star\", 2, 4,distribution=\"uniform_uncertain\")\nm = Parameter(\"m\", 2, 15, distribution=\"uniform_uncertain\")\n\nsens = LhsSensitivityStudy(Y_0, g_star, m)\nsens.add_evaluation_set(plb_rate_model, obj, yield_dc)\nsens.set_number_of_samples(num_samples)\nsens.set_working_directory(\"plb_sens\", remove_existing=True)\nsens.use_overall_objective()\nsens.make_sobol_index_study()\nsens.run_in_serial()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We once again launch the study and save the results.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "plb_sens_results = sens.launch()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With both studies complete, we can print the results for analysis.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"JC sensitivity results:\", jc_sens_results.sobol)\nprint(\"PLB sensitivity results:\", plb_sens_results.sobol)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The results are printed for each parameter and show the main effects and total \neffects, respectively.\nThese responses show that the JC model should be used since both its parameters \nhave significant main and total effects. With main effects of ~> 0.3 and total \neffects ~> 0.6, Both $Y_0$ and \n$C$ have a measurable influence on the objective and are significantly coupled.\nWhile for the PLB\nmodel, $m$ and $g_star$\nonly have a slight influence on the objective with main effects < 0.1. Even \nthe total effect of $m$ is < 0.1. This indicates they cannot be \nwell calibrated over their expected ranges with the available data and \nthis model should not be used.\n\nTo finish this study, we save the JC calibrated parameters and the \nyield vs rate data to a file for \nuse in the full finite element calibration. \n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "matcal_save(\"JC_parameters.serialized\", jc_cal_results.best.to_dict())\nmatcal_save(\"rate_data.joblib\", yield_dc)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}