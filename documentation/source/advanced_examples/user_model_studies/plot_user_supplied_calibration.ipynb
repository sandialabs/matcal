{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Calibration of Two Different Material Conductivities\nIn this section, we will cover how to run a calibration \nstudy using a model for an external \nphysics modeling software. Specifically, \nwe will be calibrating the conductivities \nof a layered material\nconsisting of a layer of stainless steel\nand  a layer of ceramic foam. We have experimental data \nfrom thermocouples placed on the free-surface of the \nstainless steel layer and at the \nsteel-foam interface while the ceramic \nwas subjected to a steady heat flux. \nWe obtain temperature versus time data from the experiments run at \ndifferent applied heat fluxes. We have preprocessed the data\nfile by removing any errant lines\nand truncating the data set to the times\nrelevant to the experiment. The preprocessed \ndata is stored in csv files named 'layered_heat_test_high_0.csv',\n'layered_heat_test_high_1.csv',  and 'layered_heat_test_low.csv'. \nWe have two data sets run in the high flux configuration, \nand one data set from\nthe low flux configuration. \n\nMatCal has no native ability to perform physics calculations, \ntherefore, this needs to be done \nby an outside program. For this case we use the Sandia \nthermal-fluids code SIERRA/Aria. Prior to running\nthis calibration, we created and tested a SIERRA/Aria input \nfile and mesh file that represents our\nexperimental configuration. The SIERRA/Aria input file \nis named 'two_material_square.i' and the mesh file \nis named 'two_material_square.g'. After creating these \nfiles, we prepare them for use in MatCal.\n\n## Preprocessing Sierra Input Files\n\nIn order for MatCal to safely pass a set of parameters \nto evaluate into our model, it uses \nAprepro to annotate the variable values at the \ntop of the input files we provide to it. To prepare\nour files, we replace our tentative parameter \nvalues in our material models with variable aliases\nin the Aprepro style curly brackets. For \ninstance we take the following line::\n\n    conductivity = constant value = 1\n\nand replace it with::\n\n    conductivity = constant value = {K_foam}\n\n``K_foam`` will be the name we assign to a parameter \nin our study. In addition to replacing the material \nparameters we wish to calibrate, we need to also have \na variable alias that relates to our different \nboundary heat fluxes. For Aria, we can do this by adding \nthe alias in the boundary condition specification:: \n\n    BC Flux for energy on surface near_heater_surface = constant value = {exp_flux}\n\nWe will use the variable alias ``exp_flux`` to make \nsure our model is run under the same state conditions as our\nexperimental data was gathered in. Now that these steps \nare complete, we can start writing our MatCal script.\n\nWe start off our script as we have in the previous examples; \nimporting MatCal and defining the parameters we\nwish to study. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<div class=\"alert alert-info\"><h4>Note</h4><p>As a reminder, the names we give our parameters \n   (``K_foam``, ``K_steel``) need to be the same names \n   used in our input file.</p></div>\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from matcal import *\n\ncond_1 = Parameter(\"K_foam\", .05 , .5, distribution=\"uniform_uncertain\")\ncond_2 = Parameter(\"K_steel\", 40, 50, distribution=\"uniform_uncertain\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The next step is to import our cleaned experimental data. \nWe have data from two different \nheat flux rates. In order for MatCal to compare \nthe correct experimental data to the correct simulation \nresults, each of the data sets imported need to have \na :class:`~matcal.core.state.State` assigned to them. Below we import the low \nheat flux data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "low_flux_data = FileData(\"layered_heat_test_low.csv\")\n\nlow_flux_state = State(\"LowFlux\", exp_flux=1e3)\nlow_flux_data.set_state(low_flux_state)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, we import the data as we have in previous examples. \nThen, we create a state and assign it to \nour data using the :meth:`~matcal.core.data.Data.set_state` method. \nPassing data with states into a MatCal study will let MatCal know\nthat it needs to run a particular simulation multiple \ntimes in each of the different experimental states. \nThis way we only need to supply one input deck for a \ngiven experimental setup no matter the number of different\nvariables changed between runs. \n\nIf we were running a Python model, the state parameters would be passed \ninto the Python function along with the study \nparameters as keyword arguments, so that both \nthe state and study parameters are accessible in the model.\n\nA state is created using a :class:`~matcal.core.state.State` object. A\n:class:`~matcal.core.state.State` object takes \nin a name for the state, in this \ncase 'LowFlux', and then keyword arguments for \nthe variables that describe that state. In this case we have\none variable ``exp_flux``, which tells our input \nfile how much heat to impose on our target surface. \n\nWe then repeat this process for the high heat flux data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "high_flux_state = State(\"HighFlux\", exp_flux=1e4)\nhigh_flux_data_0 = FileData(\"layered_heat_test_high_0.csv\")\nhigh_flux_data_1 = FileData(\"layered_heat_test_high_1.csv\")\n\nhigh_flux_data_0.set_state(high_flux_state)\nhigh_flux_data_1.set_state(high_flux_state)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The two high heat flux datasets are run with the same flux, so they share the same state. In MatCal, all states\nshould be unique, and a single state can be assigned to multiple datasets. While we wrote our data importing \nexplicitly in this example, if we had more repeats of our experiments, it would be easier for us to import \ndata using the :class:`~matcal.core.data_importer.BatchDataImporter`. \nSee `Data Importing and Manipulation`. \n\nWith our individual pieces of data imported, we then group it all together in a :class:`~matcal.core.data.DataCollection`,\nwhich is a cohesive set of data that can be used together to calibrate a given model. \n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "data_collection = DataCollection(\"temperature_data\", high_flux_data_0, high_flux_data_1, low_flux_data)\ndata_collection.plot(\"time\", \"T_middle\")\ndata_collection.plot(\"time\", \"T_bottom\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we define that model for MatCal. \n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "user_file = \"two_material_square.i\"\ngeo_file = \"two_material_square.g\"\nsim_results_file = \"two_material_results.csv\"\nmodel = UserDefinedSierraModel('aria', user_file, geo_file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "SIERRA models that we create on our own are \nimported into MatCal using the \n:class:`~matcal.sierra.models.UserDefinedSierraModel`\nclass.\nThe first argument we pass in is the name of \nthe SIERRA executable we wish to run, in our case ``aria``\nto run SIERRA/Aria. \nThe second and third arguments are \nthe file paths to the input file and mesh file, respectively. \nMatCal expects that the simulation will \nimport the mesh file from the current working directory \nwhen it is run. \nAs a result, MatCal might run into errors \nif the mesh file and input file are supplied in different directories.\nIf there are any additional files or directories needed \nto to run the model, we could just add \ntheir filepaths as additional arguments after the mesh file. \n\nThe last thing we need is to tell MatCal what results \ncsv file our Aria simulation will \nproduce. MatCal by default expects 'results.csv' to \nbe the results file produced by any model, and since ours\nhas a different name, we need to provide this to MatCal. \n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model.set_results_filename(sim_results_file)\n\n# Now that we have our model and data setup, \n# we setup and run our calibration study just like our previous examples.\n\nobjective = CurveBasedInterpolatedObjective(\"time\", \"T_middle\", \"T_bottom\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We define an objective to compare the data \nfields \"T_middle\" and \"T_bottom\" across \"time\" \nfor our experimental data and simulation data. \n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "calibration = GradientCalibrationStudy(cond_1, cond_2)\ncalibration.set_results_storage_options(results_save_frequency=3)\ncalibration.add_evaluation_set(model, objective, data_collection)\ncalibration.set_core_limit(6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We define our calibration study, telling it what \nparameters we are studying. We then assign an evaluation set to the study, \ntelling the study that it compares a given set of data, \nto the given model, in the way described by the given objective. \nLastly, we let the study know how many cores it can use. \n\nWith the calibration setup, all that is left to do is \nrun it, wait for the results and plot the completed \ncalibration results. \n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "results = calibration.launch()\nprint(results.best.to_dict())\nmake_standard_plots(\"time\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}